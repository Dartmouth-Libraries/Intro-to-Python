{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python II: Dataframes\n",
    "\n",
    "Nearly all researchers work with tabular data at one time or another. In this lesson, we will practice with **dataframes**, a Python data structure designed to work with tabular data, using the **Pandas library**. We will create our own dataframes, read in data from .csv files to a dataframe, subset and combine dataframes, and add or modify columns (variables) and observations (rows). We will also examine how these tasks work with messy and large datasets (i.e. millions or rows).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python Series (Spring 2023)\n",
    "\n",
    "All Courses on Tuesdays, 12:00 (Noon) - 1:30pm. You may take all four lessons or pick and choose. However, each lesson builds on the previous so knowing how to work with data frames, for example, will help you with the visualization lesson even if you can get by without this prior knowledge.\n",
    "\n",
    "1. The Basics (Apr. 4)\n",
    "2. **Dataframes (Apr. 25)**\n",
    "3. Visualization (May 2)\n",
    "4. Text Analysis (May 16)\n",
    "\n",
    "Note: If you want to take the whole series, you will need to sign up for each course individually at: http://dartgo.org/RRADworkshops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about Pandas, visit the webpage for the [Pandas library](https://pandas.pydata.org/).\n",
    "\n",
    "For further practice with Python and Pandas dataframes, visit:\n",
    "\n",
    "1. Software Carpentries [Pandas DataFrames](http://swcarpentry.github.io/python-novice-gapminder/08-data-frames/index.html) lesson.\n",
    "2. The **Pandas 1**, **Pandas 2**, and **Pandas 3** [tutorials offered by Constellate](https://constellate.org/tutorials).\n",
    "3. Chapter 3, [\"Data Analysis (Pandas)\"](https://melaniewalsh.github.io/Intro-Cultural-Analytics/03-Data-Analysis/01-Pandas-Basics-Part1.html) in Melanie Walsh's *Introduction to Cultural Analytics & Python*.\n",
    "\n",
    "Note: All three platforms above offer excellent lessons for learning how to perform various other tasks in Python. Check them out.\n",
    "\n",
    "Finally, don't worry about memorizing all the functions and syntax needed to work with Pandas. You can use the [Python Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) as a handy guide to remind you of some of these key functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"text-align:center;font-size:300%;\">Dataframes: The Basics<h1> \n",
    "  <img src=\"https://media.geeksforgeeks.org/wp-content/cdn-uploads/creating_dataframe1.png\" style=\"width:%40;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a particular data structure that includes:\n",
    "+ **rows** that record each observation of data\n",
    "+ **columns** that record different attributes / measures / variables for each observation\n",
    "+ **column labels** that describe the data recorded in each column\n",
    "+ **index labels** that differentiate between each observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Create a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we need to import the [**Pandas**, Python's data analysis library](https://pandas.pydata.org/) that allows us to work with dataframes. It is almost universal practice among Python users to import Pandas under the name \"pd\" to serve as a useful abbreviation we can use when calling Pandas functions. We will also import **pathlib** and **glob** to help us work with file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib, glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. There are many ways to create a dataframe:\n",
    "    + Perhaps the most common way is to load a dataset saved as a **.csv** (Comma Separated Values) file and read it in directly as a Pandas dataframe. We will introduce that method in the next section.\n",
    "    + Import information from other files that do not contain data already assembled in a two-dimensional table with rows and columns. For example, you could write a Python script iterating over 1000s of text files and create a Pandas dataframe with basic information about each text (i.e. file names, number of words, etc.)\n",
    "    + We can also create a dataframe from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this example comes from Constellate's Pandas 1 tutorial\n",
    "  ## https://lab.constellate.org/ilr-review-primary/notebooks/tdm-notebooks-2023-04-19T13%3A37%3A13.281Z/pandas-1.ipynb\n",
    "wcup = pd.DataFrame({\"Year\": [2022, \n",
    "                              2018, \n",
    "                              2014, \n",
    "                              2010, \n",
    "                              2006, \n",
    "                              2002, \n",
    "                              1998, \n",
    "                              1994, \n",
    "                              1990,\n",
    "                              1986], \n",
    "                     \"Champion\": [\"Argentina\", \n",
    "                                  \"France\", \n",
    "                                  \"Germany\", \n",
    "                                  \"Spain\", \n",
    "                                  \"Italy\", \n",
    "                                  \"Brazil\", \n",
    "                                  \"France\", \n",
    "                                  \"Brazil\", \n",
    "                                  \"Germany\", \n",
    "                                  \"Argentina\"], \n",
    "                     \"Host\": [\"Qatar\", \n",
    "                              \"Russia\", \n",
    "                              \"Brazil\", \n",
    "                              \"South Africa\", \n",
    "                              \"Germany\", \n",
    "                              \"Korea/Japan\", \n",
    "                              \"France\", \n",
    "                              \"USA\", \n",
    "                              \"Italy\", \n",
    "                              \"Mexico\"]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the above example, we are directly inputting a dataframe using the Python **dictionary** data structure. For more on Python dictionaries (click here)[https://www.w3schools.com/python/python_dictionaries.asp]. \n",
    "\n",
    "*This is beyond the scope of this lesson, but if you are curious, here is a brief explanation of how dictionaries work. ?????*\n",
    "\n",
    "Let's view what the resulting dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will come back to this dataset below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Read a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the basic Men's World Cup dataset created above, in this lesson we will also be working with the following datasets:\n",
    "\n",
    "+ The Gapminder dataset charting changing life expectancies and GDP values for countries over time. (used by Software Carpentries)\n",
    "<!--+ The Bellevue Almshouse dataset (used in [Walsh, *Intro to Cultural Analytics*](https://melaniewalsh.github.io/Intro-Cultural-Analytics/03-Data-Analysis/01-Pandas-Basics-Part1.html) and created by Anelise Hanson Shrout. Original [link to data here](https://docs.google.com/spreadsheets/d/1uf8uaqicknrn0a6STWrVfVMScQQMtzYf5I_QyhB9r7I/edit#gid=2057113261). An [essay about this dataset is here](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/).)-->\n",
    "+ Hollywood Film Dialogue dataset (also used in Walsh. Original data from Hannah Anderson and Matt Daniels, [\"Film Dialogue from 2,000 screenplays, Broken down by Gender and Age.\"](https://pudding.cool/2017/03/film-dialogue/))\n",
    "\n",
    "4. To read data in, we will use the Pandas [**read_csv** function](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). First, however, we need to create a path to the folder where our datasets are saved. We will use the **Path** function from the **pathlib** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_path = Path(\"~/shared/RR-workshop-data/gapminder\").expanduser() \n",
    "gapminder_csvpath = Path(gapminder_path, \"gapminder_all.csv\")\n",
    "csv_files = glob.glob(f\"{gapminder_path}/*.csv\")\n",
    "print(csv_files)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Now we can read in the **Gapminder dataset** using Pandas read_csv. function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df = pd.read_csv(gapminder_csvpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out this dataframe below in Jupyter Notebooks by simply typing the name of the dataframe (note: if you place any code below it, you need to wrap it in a **print()** command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick summary of what you see above from Melanie Walsh's book:\n",
    "\n",
    "There are a few important things to note about the DataFrame displayed here:\n",
    "\n",
    "+ Index\n",
    "    - The bolded ascending numbers in the very left-hand column of the DataFrame is called the Pandas Index. You can select rows based on the Index.\n",
    "    - By default, the Index is a sequence of numbers starting with zero. However, you can change the Index to something else, such as one of the columns in your dataset.\n",
    "\n",
    "+ Truncation\n",
    "    - The DataFrame is truncated, signaled by the ellipses in the middle ... of every column.\n",
    "    - The DataFrame is truncated because we set our default display settings to 100 rows. Anything more than 100 rows will be truncated. To display all the rows, we would need to alter Pandas’ default display settings yet again.\n",
    "\n",
    "+ Rows x Columns\n",
    "    - Pandas reports how many rows and columns are in this dataset at the bottom of the output (n rows x n columns).\n",
    "    - This is very useful!\n",
    "\n",
    "*In addition, I would also add that in the preview of the dataframe above - at least as viewed within JHub - you can click on a pen/highlighter icon to view the whole dataframe.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Get summary data to learn more about a dataframe\n",
    "\n",
    "6. Now, often the first thing we want to do with a new dataset is to explore the size of the dataset and the type and range of data it contains. Run the following functions and then use hashtags ```#``` to add in comments about what each does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.head() #what does the .head() method do to our dataframe?\n",
    "                    ##explain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.head(12)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.tail() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.shape #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.info() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.sample(10) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.describe() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also get summary information about individual columns. For example:\n",
    "\n",
    "gapminder_df['gdpPercap_1987'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## or:\n",
    "gapminder_df['continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercises for Parts II and III</h3>\n",
    "\n",
    "<p style=\"color:blue;\">7. Take a look at the [Python Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf). Are there any other summary data you would like to retrieve from this dataset. Try it below:</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">8. Now let's open the Film Dialogue dataset. Copy and paste the code from Part II, Numbers 4 and 5 below and then modify that code to open the film dialogue dataset. (Navigate to the film-dialogue folder using the folder directory on the left. You will need to identify the specific file path to and file name of the film dataframe).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*\\***A note about data entry and humans (and things like gender, race, class, etc.)**: When people collect data, they often have to reduce complex phenomena to individual categories. This is problematic when performed on objects that do not neatly fit into pre-existing categories (or any categories for that matter). This is especially problematic when assigned to humans. How do you reduce humans to a racial or ethnic category when those categories are, to at least some extent, social inventions? When a person comes from a mixed background? How do you reduce people to two gender categories, when many people do not feel they are adequately represented by such categories? Keep this in mind when reviewing datasets that place people into hard and fast categories (as the above dataset does for the gender of movie characters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">9. Using some of the methods introduced in Part III and the [Python Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf), answer the following questions:</p>\n",
    "<ul>\n",
    "    <li style=\"color:blue;\">How many rows and columns are there in this dataset?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "    <li style=\"color:blue;\">What are the range of dates for the films included in this dataset?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "    <li style=\"color:blue;\">How many men vs. women (** - see note above) are included in this dataset</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "    <li style=\"color:blue;\">What is the average age of film characters in this dataset?</li>\n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Access Parts of a Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">10. Let's take a look at our World Cup data again. Use the **.head()** method to output the first 5 rows of this dataset (wcup).</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. We can use the **.iloc[..., ...]** method to extract particular columns, rows, or cells. For example to retrieve the first row or first column, we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">11b. Can you guess how to extract only the last column?</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">11c. How would you retrieve the value found in the 2nd row of the 2nd column?</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. We can us **.loc[..., ...] to retrieve values, columns, or rows by their labels. For example, if we wanted to retrieve all info from the \"Champion\" column, we would simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.loc[:,\"Champion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12b. At the moment, rows are only indexed by numbers (\"0\", \"1\", \"2\" and so on). However, we can convert out \"Year\" column into an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup = wcup.set_index(\"Year\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the slight change below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12c. Now we can search the dataframe by our index (\"Year\") and by column name. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.loc[1994, \"Champion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: for the code above, our index (\"Year\") has integers not strings. So running:*\n",
    "\n",
    "```\n",
    "wcup.loc[\"1994\", \"Champion\"]\n",
    "```\n",
    "\n",
    "*will produce an error. Since 1994 is considered an integer here, we should leave the quotes out.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12d. Like many things in Python, there are often multiple ways to accomplish the same goal. For example, we can also select particular columns by simply placing the names of a column within brackets (similar to indexing and slicing lists in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bracket notation to access the column 'Champion'\n",
    "wcup['Champion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access multiple columns\n",
    "film_df[[\"title\", \"character\", \"age\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Subset, Filter, and Sort a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, when we are working with a dataset we may want to subset, filter, or sort the dataset before beginning your analysis.\n",
    "\n",
    "Many of you may already be familiar with subsetting, filtering, and sorting datasets. But, just for review, this is what we mean by these terms:\n",
    "+ **subset** - to subset a dataset is to create a smaller version of the dataset. For example, you may want to drop specific columns or rows to create a dataframe for your analysis\n",
    "\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/03_subset_columns.svg\" style=\"width:40%;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/03_subset_rows.svg\" style=\"width:40%;\">\n",
    "    \n",
    "    + **filter** - filtering a dataframe is a specific type of subsetting. For example, you may want to drop all rows in a dataframe that contain missing values. Or keep only those rows that have a value that meets a particular condition.\n",
    "+ **sort** - arrange the dataframe in a particular order. For example, you may want to sort a dataframe by a year or time column to arrange each row in chronological order. You may also sort a dataframe by multiple columns at once (i.e. sorting by year first and country second).\n",
    "    <img src = \"https://pythonexamples.org/images/python-pandas-dataframe-sort-by-index.svg\" style = \"width:40%\">\n",
    "\n",
    "Some examples of how you may want to subset, filter, or sort this lesson's dataframes: \n",
    "\n",
    "| Modification | World Cup dataset | Gapminder dataset | Film Dialogue dataset |\n",
    "| :- | :- | :- | :- |\n",
    "| **subset / filter** | create a df including only the 21st century men's World Cup champions | only review data from a set number of countries **or** for set range of years | keep only \"title\", \"gender\", and \"proportion_of_dialogue\" columns **or** only include data for film dialogue spoken by a character over 50 years old  |\n",
    "| **sort** | Sort dataframe by year, but this time in ascending order | sort dataframe by life expectancy in 2007, in descending order | sort df by proportion of dialogue |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vb. Subsetting / Filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. We can create data subsets by using the same slicing functions described in Part IV and saving them as new dataframes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup_last5 = wcup.iloc[:5,]\n",
    "wcup_last5\n",
    "# note, the head function can accomplish the exact same thing\n",
    "#i.e. wcup_last5 = wcup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\"><p style=\"color:green\">13b. Let's take a look at the film_df again by using the .head() method.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_subset = film_df[['release_year', 'title', 'proportion_of_dialogue']]\n",
    "film_subset.head()\n",
    "\n",
    "# notice: in the 1st line of code above, we not only selected 3 columns to keep but we also re-arranged their order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: this does the same as above, only this time using the .loc[] method\n",
    "film_subset = film_df.loc[:,['release_year', 'title', 'proportion_of_dialogue']]\n",
    "film_subset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. We can drop specific columns using the **.drop()** method for Pandas dataframes. For example, if we want to drop the \"Host\" column from our World Cup dataset, we could run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wcup.shape)\n",
    "print(wcup.head(2))\n",
    "wcup2 = wcup.drop(columns = \"Host\")  #note: we need to add \"wcup2 =\" to save the changes to our original wcup dataframe as \"wcup2\"\n",
    "                                    ##you could also just replace the original \"wcup\" by writing wcup = wcup.drop(...)\n",
    "                                    ## however, often it is helpful to keep both the original, full dataframe and the smaller, subsetted one\n",
    "print(wcup2.shape)\n",
    "print(wcup2.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to drop specific columns or rows using .drop(). See the [Pandas 2 Constellate lesson](https://lab.constellate.org/monist-language/notebooks/tdm-notebooks-2023-04-19T18%3A59%3A16.317Z/pandas-2.ipynb) for some additional examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Commonly, for example, we may want to drop observations (rows) containing null data (warning: you should always consider what this removal does to the representative nature of your dataset!). We can use the **.dropna()** method. See some examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(film_df.shape)\n",
    "film_df_no_nas = film_df.dropna()\n",
    "print(film_df_no_nas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15b. Temporarily or permanently changing a dataframe: Most methods in Python just temporarily change a dataframe unless you assign the modified dataframe to a variable. For example:\n",
    "\n",
    "```\n",
    "film_df.dropna()\n",
    "```\n",
    "just outputs a version of film_df with all NAs and null values removed, but does not save it to memory. If we wanted to replace the original \"film_df\" we can simply assign it the same name as follows:\n",
    "\n",
    "```\n",
    "film_df = film_df.dropna()\n",
    "```\n",
    "Or we can save it under a new name as we did above:\n",
    "```\n",
    "film_df_no_nas = film_df.dropna()\n",
    "```\n",
    "\n",
    "Finally, we can also use the \"inplace\" argument to do the same:\n",
    "\n",
    "```\n",
    "film_df.dropna(inplace = True)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15c. You can also drop columns with missing values (this is much rarer than dropping rows with missing values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df_dropcols = film_df.dropna(axis = 1)    #for Pandas, rows are axis 0 and columns are axis 1\n",
    "#film_df_dropcols = film_df.dropna(axis = \"columns\") # this does the same thing! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15d. More commonly, you may want to remove rows that are missing values for specific columns. For example, if you want to analyze the age of characters / actors given speaking roles in films, you would want to remove any characters (rows) for which we lack age data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(film_df.shape)\n",
    "film_df_age = film_df.dropna(subset = \"age\")\n",
    "film_df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vc. Filtering a dataframe by a condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16a. To filter a dataframe by a condition, first we need to define the filter itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df['continent'] == 'Africa'   #remember: \"=\" indicates an assignment and \"==\" indicates a comparison returning True if both sides are equal and False if not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16b. We can then assign this specific filter to a variable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (gapminder_df['continent'] == 'Africa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16c. And use that filter to create a subset of our original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_Africa = gapminder_df.loc[filt]\n",
    "gapminder_Africa.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16d. We can also filter by multiple conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_filt = (film_df['release_year'] >= 1990) & (film_df['release_year'] < 2000)\n",
    "nineties_films = film_df.loc[years_filt]     #note: you cannot begin a variable name with a number, thus 90s_films would raise an error\n",
    "nineties_films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine multiple filters to create an even smaller and more specific subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_filt = (film_df['gross'] > 800)\n",
    "nineties_blockbusters = film_df.loc[years_filt & gross_filt]\n",
    "nineties_blockbusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercise for Part V. Subsets and Filters</h3>\n",
    "\n",
    "<p style=\"color:blue;\">17. Filter and subset the film_df to create a new dataset with only films from **a decade of your choosing**.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercise for Part Vb: Subsetting</h3>\n",
    "\n",
    "<p style=\"color:blue;\">17b. Using the methods you learned above, what are some different ways you could go about subsetting and filtering the gapminder dataset so that it includes only data from Asia and only for the twenty-first century.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some possible solutions here: \n",
    "\n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">17c. Implement one of your proposed solutions above to subset the gapminder dataset as described in 17b.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vd. Sorting a dataframe\n",
    "\n",
    "18. We can sort a dataframe by the values in one column or in multiple columns using the **.sortvalues()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.sort_values(by = ['release_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. We can sort columns in descending order by adding the argument ```ascending = False``` (the default is \"ascending = True\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.sort_values(by = ['release_year'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19b. When sorting by multiple columns, we need to specify which will be sorted in ascending rather than descending order using a list of the same length as the list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_df.sort_values(by = ['release_year', 'title', 'character'], ascending = [False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercise for Part Vd. Sorting</h3>\n",
    "\n",
    "<p style=\"color:blue;\">20. Sort the gapminder dataframe by first the \"continent\" column and then the \"country\" column, but in descending (not ascending) order for each.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.sort_values(by = ['continent', 'country'], ascending = [False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">20b. Sort the Gapminder dataframe in three ways to answer the following three questions:</p>\n",
    "<ul>\n",
    "<li style = \"color:blue;\">Which five countries had the largest population in 2007?</li>\n",
    "<li style = \"color:blue;\">Which five countries had the highest GDP in 2007?</li>\n",
    "<li style = \"color:blue;\">Which five countries had the highest life expectancy in 2007?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df[[\"continent\", \"country\", \"pop_2007\"]].sort_values(by = \"pop_2007\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df[[\"continent\", \"country\", \"gdpPercap_2007\"]].sort_values(by = \"gdpPercap_2007\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df[[\"continent\", \"country\", \"lifeExp_2007\"]].sort_values(by = \"lifeExp_2007\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Modify a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways you can modify an existing dataframe.\n",
    "\n",
    "21. You can change column names. First, let's review the names of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup3 = wcup.rename(columns = {'Host': 'home_country'})\n",
    "wcup3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Change values in the dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup.loc[2022, \"Champion\"] = \"Messi!!\"\n",
    "wcup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. We can apply functions across an entire column using Pandas' **.apply()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uppercase(text):   #In Python you use \"def\" to define a function, give the function a name, and then you have the option of reading in additional arguments\n",
    "    text_upper = text.upper()\n",
    "    return(text_upper)\n",
    "\n",
    "wcup['Host'].apply(make_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23b. The code above only temporarily created a new \"Host\" column all in uppercase. Modify the code cell below so that there is a new column to store the uppercase values from the Host column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcup['Host'].apply(make_uppercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. You can also create a new column using operands. For example, in the Gapminder dataset, we may want to calculate population change from 2002 to 2007 by subtracting the former from the latter. We can so by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df[\"pop_chg_02-07\"] = gapminder_df[\"pop_2007\"] - gapminder_df[\"pop_2002\"]\n",
    "\n",
    "#to better see the results, let's just output the relevant columns\n",
    "gapminder_df[['country', 'continent', 'pop_2002', 'pop_2007', 'pop_chg_02-07']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also sort the values to identify those countries that lost population between 2002 and 2007\n",
    "gapminder_df[['country', 'continent', 'pop_2002', 'pop_2007', 'pop_chg_02-07']].sort_values(by = \"pop_chg_02-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercises: Part VI Modifying a Dataframe</h3>\n",
    "\n",
    "<p style=\"color:blue;\">25. Following the code above, create a new column and then sort it to help you answer one of the following questions (you choose): </p>\n",
    "<ul>\n",
    "<li style=\"color:blue;\">Which country's GDP improved the most between 1952 and 2007?</li>\n",
    "<li style=\"color:blue;\">Which country's life expectancy improved the most between 1952 and 2007?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">26. Using a custom made function and the .apply() method create a new column in the film_df with each movie character's name capitalized.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Split-Apply-Combine\n",
    "\n",
    "<img src = \"https://www.oreilly.com/api/v2/epubs/9781783985128/files/graphics/5128OS_09_01.jpg\" style=\"width:40%\">\n",
    "\n",
    "A commonly used data analysis strategy is **split-apply-combine**:\n",
    "+ **split** the problem / data into manageable pieces\n",
    "+ **apply** some calculations or analysis to the pieces\n",
    "+ **combine** the parts back into a whole\n",
    "\n",
    "For computational data science this means (from [Python Pandas documentation](https://pandas.pydata.org/docs/user_guide/groupby.html)):\n",
    "```\n",
    "    * Splitting the data into groups based on some criteria\n",
    "    * Applying a function to each group independently\n",
    "    * Combining the results into a data structure\n",
    "```\n",
    "\n",
    "Let's examine how this strategy may work for the datasets we have been working with. In our Gapminder dataset, for example, we may want to explore larger trends at the continent level. So we could:\n",
    "+ **split** the overall dataset by continent, creating separate Africa, Asia, North America, South America, Oceania, and Europe datasets.\n",
    "+ **apply** some calculations to each continental dataset; i.e. What is the average GDP and life expectancy of each continent in different years? Or what has been the average rate of change in these values from one five year interval to the next?\n",
    "+ **combine** the data back together to compare changes in productivity (as measured by GDP) and health (as measured by life expectancy) by continent and over time.\n",
    "\n",
    "Different applications apply this strategy in different ways. In Excel, you would use pivot tables, SQL the \"group by\" operator, and in R you may use the plyr package.\n",
    "\n",
    "With Pandas, we can use the **.groupby()**, **.agg()**, and **.apply()** functions to do this. \n",
    "+ **.groupby()** - *splits* a dataset into separate groups\n",
    "+ **.agg()** - used to calculate multiple statistics per group in one calculation\n",
    "+ **.apply()** - applies a function across an entire column (or row) in a Pandas dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-examine the contents of our Gapminder dataframe. \n",
    "\n",
    "27. Use the .head() method to output its first five rows and use the .columns method to output summary information about this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIIb: Groupby()\n",
    "\n",
    "*This first few cells of this section are adapted from Constellate's [3rd Pandas tutorial](https://lab.constellate.org/practical-diabetes-methods/notebooks/tdm-notebooks-2023-04-20T12%3A35%3A07.477Z/pandas-3.ipynb).*\n",
    "\n",
    "28. Groupby is a powerful function built into Pandas that you can use to summarize your data. Groupby splits the data into different groups on a variable of your choice. \n",
    "\n",
    "To learn more about using Pandas **.groupby()** to split-apply-combine data, see the [documentation here](https://pandas.pydata.org/docs/user_guide/groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by continent\n",
    "gapminder_df.groupby('continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. The groupby() method returns a GroupBy object which describes how the rows of the original dataset have been split by the selected variable. You can actually see how the rows of the original dataframe have been grouped using the ```groups``` attribute after applying ```groupby().```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the rows have been grouped\n",
    "gapminder_df.groupby('continent').groups\n",
    "#Note: this dataset had already been sorted by continent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Of course, we don't just stop at grouping data. Grouping data is just a step towards data query. After we apply the .groupby() method, we can actually use different Pandas methods to query the data. For example, how do we get the number of documents in each docType by publicationYear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series storing the number of documents in each doc type by year\n",
    "gapminder_df.groupby('continent').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the **.agg()** (aggregate) method to choose what functions we will **apply** to each group to allow us to **combine** the data back together.\n",
    "\n",
    "The general formula for applying functions using the aggregate (.agg()) method:\n",
    "\n",
    "```\n",
    "df_name.groupby('col_name').agg({dict assigning a function to each column we want to aggregate})\n",
    "\n",
    "```\n",
    "where the format for each dictionary is as follows:\n",
    "```\n",
    "{'name_of_col1_to_keep': 'function_to_apply_to_this_col', 'name_of_col2_to_keep': 'function_to_apply_to_this_col'}\n",
    "```\n",
    "\n",
    "Some commonly used functions with groupby ([click here](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#computations-descriptive-stats) for a full list):\n",
    "+ .count(), .mean(), .min(), .max(), .sum()\n",
    "\n",
    "31. With this in mind, examine the following line of code. What do you guess it does? Run it and see if you were correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_df.groupby('continent').agg({'lifeExp_2007':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. We can use the .agg() method to apply multiple functions to multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pop_chg = gapminder_df.groupby('continent').agg({'pop_2002':'sum', 'pop_2007': 'sum'})\n",
    "cont_pop_chg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. We can then use these two columns in the continental dataset to calculate percent population change between 2002 and 2007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pop_chg['pct_chg_02-07'] = 100 * (cont_pop_chg['pop_2007'] - cont_pop_chg['pop_2002']) / cont_pop_chg['pop_2002']\n",
    "cont_pop_chg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><h3 style=\"color:blue;\">Exercises Part VII: Split-Apply-Combine</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><p style=\"color:blue;\">34. Using what you learned above, group the gapminder_df by continent again, but this time calculating the average change in life expectancy for each continent between 1952 and 2007.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
